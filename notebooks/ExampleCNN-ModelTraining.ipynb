{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%pylab is deprecated, use %matplotlib inline and import the required libraries.\n",
      "Populating the interactive namespace from numpy and matplotlib\n",
      "c:\\Cadena2019PlosCB\n",
      "path:c:\\Cadena2019PlosCB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Cadena2019PlosCB\\.research6\\Lib\\site-packages\\IPython\\core\\magics\\osm.py:417: UserWarning: using dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Cadena2019PlosCB\\cnn_sys_ident\\cnnsysid.py:23: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import importlib\n",
    "\n",
    "%cd ..\n",
    "p = os.getcwd()\n",
    "print(\"path:\" + p)\n",
    "if p not in sys.path:\n",
    "    sys.path.append(p)\n",
    "    \n",
    "from cnn_sys_ident.data import Dataset, MonkeyDataset\n",
    "from cnn_sys_ident.cnnsysid import ConvNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To train with all data, use Dataset.get_clean_data(). To use specific types of images for training and testing, run the commented code and secify in Dataset.add_train_test_types() the types for training and/or testing as a list. For example: Dataset.add_train_test_types(data_dict, types_train=['conv1','conv2'], types_test=['conv4']) for training with types conv1 and conv2 and testing on conv4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_dict = Dataset.load_data()\n",
    "# data_dict = Dataset.manage_repeats(data_dict)\n",
    "# data_dict = Dataset.preprocess_nans(data_dict)\n",
    "# data_dict = Dataset.add_train_test_types(data_dict, types_train='all', types_test='all')\n",
    "\n",
    "# With a wrapper function\n",
    "data_dict = Dataset.get_clean_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = MonkeyDataset(data_dict, seed=1000, train_frac=0.8 ,subsample=2, crop = 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ConvNet(data, log_dir='monkey', log_hash='cnn', obs_noise_model='poisson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log dir: cnn\n",
      "Average variances | validation set: 2.586168 | test set: 1.457066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Cadena2019PlosCB\\cnn_sys_ident\\data.py:180: RuntimeWarning: Mean of empty slice\n",
      "  return self.images_test, np.nanmean(self.nanarray(self.real_resps_test,self.responses_test),axis=0)\n"
     ]
    }
   ],
   "source": [
    "print('Log dir: %s' % model.log_hash)\n",
    "_, test_responses = data.test_av()\n",
    "_, val_responses, real_val_resps = data.val()\n",
    "_, tr_responses, real_tr_resps = data.train()\n",
    "\n",
    "val_array = data.nanarray(real_val_resps,val_responses)\n",
    "tr_array = data.nanarray(real_tr_resps,tr_responses)\n",
    "print('Average variances | validation set: %f | test set: %f' % (np.nanmean(np.nanvar(val_array, axis=0)), np.nanmean(np.nanvar(test_responses, axis=0))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a 3 layer CNN with filters of sizes 13x13x32, 3x3x32, and 3x3x32.\n",
    "Each convolutional layer will have stride 1, and will be padded according to 'valid', 'same', and 'same'\n",
    "Additionally, we will impose a smoothness 2d penalty of 3e-4 in the filters of the first layer and a 2.5e-4 L1 penalty on the 2nd and 3rd layer. \n",
    "The readout will have a sparsity L1 penalty of 2e-4 and finally, the output nonlinearity will have a smoothing penalty of 0 in this case (check paper for details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Cadena2019PlosCB\\.research6\\Lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer_v1.py:1694: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  warnings.warn('`layer.apply` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Cadena2019PlosCB\\.research6\\Lib\\site-packages\\keras\\layers\\normalization\\batch_normalization.py:581: _colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From c:\\Cadena2019PlosCB\\cnn_sys_ident\\cnnsysid.py:102: add_loss (from tf_slim.losses.loss_ops) is deprecated and will be removed after 2016-12-30.\n",
      "Instructions for updating:\n",
      "Use tf.losses.add_loss instead.\n",
      "WARNING:tensorflow:From c:\\Cadena2019PlosCB\\cnn_sys_ident\\cnnsysid.py:119: get_total_loss (from tf_slim.losses.loss_ops) is deprecated and will be removed after 2016-12-30.\n",
      "Instructions for updating:\n",
      "Use tf.losses.get_total_loss instead.\n",
      "WARNING:tensorflow:From c:\\Cadena2019PlosCB\\.research6\\Lib\\site-packages\\tf_slim\\losses\\loss_ops.py:236: get_losses (from tf_slim.losses.loss_ops) is deprecated and will be removed after 2016-12-30.\n",
      "Instructions for updating:\n",
      "Use tf.losses.get_losses instead.\n",
      "WARNING:tensorflow:From c:\\Cadena2019PlosCB\\.research6\\Lib\\site-packages\\tf_slim\\losses\\loss_ops.py:238: get_regularization_losses (from tf_slim.losses.loss_ops) is deprecated and will be removed after 2016-12-30.\n",
      "Instructions for updating:\n",
      "Use tf.losses.get_regularization_losses instead.\n"
     ]
    }
   ],
   "source": [
    "model.build(filter_sizes=[13, 3, 3],\n",
    "          out_channels=[32, 32, 32],\n",
    "          strides=[1, 1, 1],\n",
    "          paddings=['VALID', 'SAME', 'SAME'],\n",
    "          smooth_weights=[0.0003, 0, 0],\n",
    "          sparse_weights=[0.0, 0.00025, 0.00025],\n",
    "          readout_sparse_weight= 0.0002,\n",
    "          output_nonlin_smooth_weight = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 100 | Loss: 0.27416956 | poisson: 0.24625862 | L1 readout: 0.020777594 | L1 conv: 0.003887755 | L2 conv: 0.003245623 | Var(test): 0.1766 | Var(val): 0.1760\n",
      "Step 200 | Loss: 0.2563615 | poisson: 0.2256827 | L1 readout: 0.023690213 | L1 conv: 0.0043907613 | L2 conv: 0.0025978223 | Var(test): 0.2551 | Var(val): 0.2562\n",
      "Step 300 | Loss: 0.2488889 | poisson: 0.21771507 | L1 readout: 0.023653585 | L1 conv: 0.0050326884 | L2 conv: 0.0024875605 | Var(test): 0.2710 | Var(val): 0.2714\n",
      "Step 400 | Loss: 0.24185035 | poisson: 0.21073842 | L1 readout: 0.023328558 | L1 conv: 0.005291893 | L2 conv: 0.0024914816 | Var(test): 0.3099 | Var(val): 0.3105\n",
      "Step 500 | Loss: 0.2389785 | poisson: 0.20857464 | L1 readout: 0.022500487 | L1 conv: 0.0053789224 | L2 conv: 0.00252447 | Var(test): 0.3301 | Var(val): 0.3286\n",
      "Step 600 | Loss: 0.2353652 | poisson: 0.20586921 | L1 readout: 0.02136114 | L1 conv: 0.0055734366 | L2 conv: 0.002561408 | Var(test): 0.2951 | Var(val): 0.2954\n",
      "Step 700 | Loss: 0.23235771 | poisson: 0.20284085 | L1 readout: 0.0212878 | L1 conv: 0.005632899 | L2 conv: 0.002596164 | Var(test): 0.3587 | Var(val): 0.3617\n",
      "Step 800 | Loss: 0.23227265 | poisson: 0.20362626 | L1 readout: 0.020351494 | L1 conv: 0.0056755575 | L2 conv: 0.0026193296 | Var(test): 0.3494 | Var(val): 0.3524\n",
      "Step 900 | Loss: 0.22987026 | poisson: 0.20145129 | L1 readout: 0.020009784 | L1 conv: 0.0057701394 | L2 conv: 0.0026390564 | Var(test): 0.3662 | Var(val): 0.3694\n",
      "Step 1000 | Loss: 0.22914906 | poisson: 0.20101662 | L1 readout: 0.019643575 | L1 conv: 0.0058326535 | L2 conv: 0.0026562002 | Var(test): 0.3676 | Var(val): 0.3711\n",
      "Step 1100 | Loss: 0.22955723 | poisson: 0.20196922 | L1 readout: 0.01908025 | L1 conv: 0.0058483733 | L2 conv: 0.002659384 | Var(test): 0.3652 | Var(val): 0.3680\n",
      "Step 1200 | Loss: 0.22808099 | poisson: 0.2007506 | L1 readout: 0.018746415 | L1 conv: 0.0059147533 | L2 conv: 0.0026692224 | Var(test): 0.3810 | Var(val): 0.3855\n",
      "Step 1300 | Loss: 0.22728752 | poisson: 0.20002267 | L1 readout: 0.018768802 | L1 conv: 0.005823116 | L2 conv: 0.0026729403 | Var(test): 0.3957 | Var(val): 0.4014\n",
      "Step 1400 | Loss: 0.22737937 | poisson: 0.2009642 | L1 readout: 0.017893145 | L1 conv: 0.005838521 | L2 conv: 0.0026834854 | Var(test): 0.3765 | Var(val): 0.3819\n",
      "Step 1500 | Loss: 0.22857897 | poisson: 0.20224027 | L1 readout: 0.017836124 | L1 conv: 0.0058270264 | L2 conv: 0.0026755314 | Var(test): 0.3784 | Var(val): 0.3795\n",
      "Step 1600 | Loss: 0.22943857 | poisson: 0.20288382 | L1 readout: 0.017995957 | L1 conv: 0.0058785416 | L2 conv: 0.002680259 | Var(test): 0.4006 | Var(val): 0.4031\n",
      "Step 1700 | Loss: 0.2270185 | poisson: 0.20095614 | L1 readout: 0.017500276 | L1 conv: 0.0058755977 | L2 conv: 0.0026864973 | Var(test): 0.4161 | Var(val): 0.4225\n",
      "Step 1800 | Loss: 0.22572292 | poisson: 0.19991612 | L1 readout: 0.017237548 | L1 conv: 0.0058858357 | L2 conv: 0.002683414 | Var(test): 0.3775 | Var(val): 0.3802\n",
      "Step 1900 | Loss: 0.22378403 | poisson: 0.19855711 | L1 readout: 0.016737683 | L1 conv: 0.005809734 | L2 conv: 0.002679499 | Var(test): 0.3877 | Var(val): 0.3916\n",
      "Step 2000 | Loss: 0.22378764 | poisson: 0.19838917 | L1 readout: 0.016854279 | L1 conv: 0.0058670626 | L2 conv: 0.002677119 | Var(test): 0.4094 | Var(val): 0.4127\n",
      "Step 2100 | Loss: 0.22422807 | poisson: 0.1991231 | L1 readout: 0.016564772 | L1 conv: 0.005866356 | L2 conv: 0.0026738541 | Var(test): 0.3926 | Var(val): 0.3966\n",
      "Step 2200 | Loss: 0.22354625 | poisson: 0.19877005 | L1 readout: 0.016172113 | L1 conv: 0.0059320256 | L2 conv: 0.0026720783 | Var(test): 0.3937 | Var(val): 0.3982\n",
      "Step 2300 | Loss: 0.2233361 | poisson: 0.19874445 | L1 readout: 0.015940942 | L1 conv: 0.0059785303 | L2 conv: 0.0026721682 | Var(test): 0.3892 | Var(val): 0.3944\n",
      "Step 2400 | Loss: 0.22436866 | poisson: 0.19987164 | L1 readout: 0.01587034 | L1 conv: 0.005952053 | L2 conv: 0.0026746206 | Var(test): 0.3885 | Var(val): 0.3940\n",
      "Step 2500 | Loss: 0.22188738 | poisson: 0.19730678 | L1 readout: 0.015950583 | L1 conv: 0.005957406 | L2 conv: 0.0026726048 | Var(test): 0.4140 | Var(val): 0.4198\n",
      "Step 2600 | Loss: 0.22268246 | poisson: 0.1981066 | L1 readout: 0.015873984 | L1 conv: 0.006024571 | L2 conv: 0.0026773133 | Var(test): 0.4135 | Var(val): 0.4183\n",
      "Step 2700 | Loss: 0.22279906 | poisson: 0.1986243 | L1 readout: 0.015388136 | L1 conv: 0.0061088526 | L2 conv: 0.0026777883 | Var(test): 0.4320 | Var(val): 0.4348\n",
      "Step 2800 | Loss: 0.22252226 | poisson: 0.19832247 | L1 readout: 0.015477124 | L1 conv: 0.006040299 | L2 conv: 0.0026823545 | Var(test): 0.4080 | Var(val): 0.4130\n",
      "Step 2900 | Loss: 0.22477017 | poisson: 0.20074199 | L1 readout: 0.015426992 | L1 conv: 0.005924122 | L2 conv: 0.002677048 | Var(test): 0.4123 | Var(val): 0.4139\n",
      "Step 3000 | Loss: 0.22175816 | poisson: 0.19804029 | L1 readout: 0.01506537 | L1 conv: 0.005969951 | L2 conv: 0.0026825573 | Var(test): 0.4144 | Var(val): 0.4188\n",
      "Step 3100 | Loss: 0.22150387 | poisson: 0.19769935 | L1 readout: 0.015107731 | L1 conv: 0.0060120216 | L2 conv: 0.0026847601 | Var(test): 0.4095 | Var(val): 0.4166\n",
      "Step 3200 | Loss: 0.22142544 | poisson: 0.19769783 | L1 readout: 0.015029908 | L1 conv: 0.0060174167 | L2 conv: 0.0026802917 | Var(test): 0.4127 | Var(val): 0.4166\n",
      "Step 3300 | Loss: 0.22558497 | poisson: 0.20160916 | L1 readout: 0.015074786 | L1 conv: 0.0062136715 | L2 conv: 0.0026873555 | Var(test): 0.4813 | Var(val): 0.4859\n",
      "Step 3400 | Loss: 0.22311874 | poisson: 0.1994209 | L1 readout: 0.01487716 | L1 conv: 0.0061324835 | L2 conv: 0.0026882007 | Var(test): 0.4259 | Var(val): 0.4314\n",
      "INFO:tensorflow:Restoring parameters from c:\\Cadena2019PlosCB\\train_logs\\monkey\\cnn\\best.ckpt\n",
      "Reducing learning rate to 0.000333\n",
      "Step 2600 | Loss: 0.21540305 | poisson: 0.19410543 | L1 readout: 0.013539449 | L1 conv: 0.005092691 | L2 conv: 0.0026654727 | Var(test): 0.4008 | Var(val): 0.4063\n",
      "Step 2700 | Loss: 0.21529199 | poisson: 0.1942332 | L1 readout: 0.013523672 | L1 conv: 0.0048768893 | L2 conv: 0.0026582354 | Var(test): 0.4026 | Var(val): 0.4083\n"
     ]
    }
   ],
   "source": [
    "learning_rate=0.001\n",
    "for lr_decay in range(3):\n",
    "    training = model.train(max_iter=10000, val_steps=100, save_steps=10000, early_stopping_steps=10, batch_size=256, learning_rate=learning_rate)\n",
    "    for (i, (logl, readout_sparse, conv_sparse, smooth, total_loss, pred)) in training:\n",
    "        result = model.eval()\n",
    "        print('Step %d | Loss: %s | %s: %s | L1 readout: %s | L1 conv: %s | L2 conv: %s | Var(test): %.4f | Var(val): %.4f' % \\\n",
    "              (i, total_loss, model.obs_noise_model, logl, readout_sparse, conv_sparse, smooth, np.mean(np.var(pred, axis=0)), np.mean(np.var(result[-1], axis=0))))\n",
    "           \n",
    "    learning_rate /= 3\n",
    "    print('Reducing learning rate to %f' % learning_rate)\n",
    "print('Done fitting')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Performance of the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.performance_test()\n",
    "eve = model.eve.mean()\n",
    "print('Explainable variance explained on test set: {}'.format(eve))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.performance_val()\n",
    "eve_val = model.eve_val.mean()\n",
    "print('Explainable variance explained on validation set: {}'.format(eve_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_correlation_valset = model.evaluate_avg_corr_val()\n",
    "print('Mean single trial correlation on validation set: {}'.format(avg_correlation_valset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
