{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import importlib\n",
    "\n",
    "%cd ..\n",
    "p = os.getcwd()\n",
    "print(\"path:\" + p)\n",
    "if p not in sys.path:\n",
    "    sys.path.append(p)\n",
    "    \n",
    "from cnn_sys_ident.data import Dataset, MonkeyDataset\n",
    "from cnn_sys_ident.lnpsysid import LNP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_dict = Dataset.load_data()\n",
    "# data_dict = Dataset.manage_repeats(data_dict)\n",
    "# data_dict = Dataset.preprocess_nans(data_dict)\n",
    "# data_dict = Dataset.add_train_test_types(data_dict, types_train='all', types_test='all')\n",
    "\n",
    "# With a wrapper function\n",
    "data_dict = Dataset.get_clean_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = MonkeyDataset(data_dict, seed=1000, train_frac=0.8 ,subsample=2, crop = 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LNP(data, log_dir='monkey', log_hash='lnp', obs_noise_model='poisson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Log dir: %s' % model.log_hash)\n",
    "_, test_responses = data.test_av()\n",
    "_, val_responses, real_val_resps = data.val()\n",
    "_, tr_responses, real_tr_resps = data.train()\n",
    "\n",
    "val_array = data.nanarray(real_val_resps,val_responses)\n",
    "tr_array = data.nanarray(real_tr_resps,tr_responses)\n",
    "print('Average variances | validation set: %f | test set: %f' % (np.nanmean(np.nanvar(val_array, axis=0)), np.nanmean(np.nanvar(test_responses, axis=0))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.build(smooth_reg_weight=0.5,\n",
    "            sparse_reg_weight=0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate=3e-4\n",
    "for lr_decay in range(3):\n",
    "    training = model.train(max_iter=10000,\n",
    "                         val_steps=100,\n",
    "                         save_steps=1000,\n",
    "                         early_stopping_steps=5,\n",
    "                         learning_rate=learning_rate)\n",
    "    for (i, (logl, total_loss, mse, pred)) in training:\n",
    "        print('Step %d | Total loss: %s | %s: %s | MSE: %s | Var(y): %s' % (i, total_loss, model.obs_noise_model, logl, mse, np.mean(np.var(pred, axis=0))))\n",
    "    learning_rate /= 3\n",
    "    print('Reducing learning rate to %f' % learning_rate)\n",
    "\n",
    "print('Done fitting')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Performance of the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.performance_test()\n",
    "eve = model.eve.mean()\n",
    "print('Explainable variance explained on test set: {}'.format(eve))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.performance_val()\n",
    "eve_val = model.eve_val.mean()\n",
    "print('Explainable variance explained on validation set: {}'.format(eve_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_correlation_valset = model.evaluate_avg_corr_val()\n",
    "print('Mean single trial correlation on validation set: {}'.format(avg_correlation_valset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
